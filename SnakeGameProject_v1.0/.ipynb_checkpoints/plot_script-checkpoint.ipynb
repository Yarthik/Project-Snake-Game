{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "republican-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def smooth(data, k):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        num_episodes = data.shape[1]\n",
    "        num_runs = data.shape[0]\n",
    "    \n",
    "        smoothed_data = np.zeros((num_runs, num_episodes))\n",
    "\n",
    "        for i in range(num_episodes):\n",
    "            if i < k:\n",
    "                smoothed_data[:, i] = np.mean(data[:, :i+1], axis = 1)   \n",
    "            else:\n",
    "                smoothed_data[:, i] = np.mean(data[:, i-k:i+1], axis = 1)    \n",
    "\n",
    "        return smoothed_data\n",
    "    else:\n",
    "        num_episodes = len(data)\n",
    "        num_runs = 1\n",
    "\n",
    "        smoothed_data = np.zeros((num_runs, num_episodes))\n",
    "\n",
    "        for i in range(num_episodes):\n",
    "            if i < k:\n",
    "                smoothed_data[:, i] = np.mean(data[:i+1])\n",
    "            else:\n",
    "                smoothed_data[:, i] = np.mean(data[i-k:i+1])\n",
    "        \n",
    "        return smoothed_data\n",
    "\n",
    "\n",
    "# Function to plot result\n",
    "def plot_result1(data_name_array, direct=False, k=5):\n",
    "    plt_agent_sweeps = []\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    max_list = []\n",
    "\n",
    "    for data_name in data_name_array:\n",
    "        # load data\n",
    "        if not direct:\n",
    "            filename = 'sum_reward_{}'.format(data_name).replace('.','')\n",
    "            sum_reward_data = np.load('{}/{}.npy'.format(\"results/\", filename))\n",
    "\n",
    "        # smooth data\n",
    "        else:\n",
    "            sum_reward_data = data_name_array[data_name]\n",
    "\n",
    "        smoothed_sum_reward = smooth(data=sum_reward_data, k=k)\n",
    "        max_list.append(max(smoothed_sum_reward[0]))\n",
    "        mean_smoothed_sum_reward = np.mean(smoothed_sum_reward, axis = 0)\n",
    "\n",
    "        plot_x_range = np.arange(0, mean_smoothed_sum_reward.shape[0])\n",
    "        graph_current_agent_sum_reward, = ax.plot(plot_x_range, mean_smoothed_sum_reward[:], label=data_name)\n",
    "        plt_agent_sweeps.append(graph_current_agent_sum_reward)\n",
    "\n",
    "    max_to_hundred = int(math.ceil(max(max_list) / 100.0)) * 100\n",
    "    \n",
    "    ax.legend(handles=plt_agent_sweeps, fontsize = 13)\n",
    "    ax.set_title(\"Learning Curve\", fontsize = 15)\n",
    "    ax.set_xlabel('Episodes', fontsize = 14)\n",
    "    ax.set_ylabel(\"Sum\\nof\\n\\nreward\\nduring\\nepisode\", rotation=0, labelpad=10, fontsize = 11)\n",
    "    ax.set_ylim([-200, max_to_hundred])\n",
    "    plt.show()     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-timothy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
